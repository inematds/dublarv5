services:
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: inemavox-api
    ports:
      - "8010:8010"
    volumes:
      # Jobs directory (workdirs, checkpoints, output)
      - ./jobs:/app/jobs
      # Cache de modelos HuggingFace (persistir entre rebuilds)
      - huggingface-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
    # Network host para acessar Ollama no localhost:11434
    network_mode: host
    environment:
      - JOBS_DIR=/app/jobs
      - PIPELINE_SCRIPT=/app/dublar_pro_v5.py
      - PYTHON_BIN=python
    restart: unless-stopped

  web:
    build:
      context: ./web
      dockerfile: Dockerfile
    container_name: inemavox-web
    ports:
      - "3010:3010"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8010
    depends_on:
      - api
    restart: unless-stopped

volumes:
  huggingface-cache:
